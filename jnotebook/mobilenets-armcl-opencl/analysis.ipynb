{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [cknowledge.org/ai](http://cknowledge.org/ai): Crowdsourcing benchmarking and optimization of AI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [Reproducible Quality-Efficient Systems Tournaments](http://cknowledge.org/request) ([ReQuEST initiative](http://cknowledge.org/request.html#organizers))\n",
    "* [AI artifacts](http://cknowledge.org/ai-artifacts) (cTuning foundation)\n",
    "* [Android app](https://play.google.com/store/apps/details?id=openscience.crowdsource.video.experiments) (dividiti)\n",
    "* [Desktop app](https://github.com/dividiti/ck-crowdsource-dnn-optimization) (dividiti)\n",
    "* [CK-Caffe](https://github.com/dividiti/ck-caffe) (Berkeley)\n",
    "* [CK-Caffe2](https://github.com/ctuning/ck-caffe2) (Facebook)\n",
    "* [CK-CNTK](https://github.com/ctuning/ck-cntk) (Microsoft)\n",
    "* [CK-KaNN](https://github.com/dividiti/ck-kann) (Kalray)\n",
    "* [CK-MVNC](https://github.com/ctuning/ck-mvnc) (Movidius / Intel)\n",
    "* [CK-MXNet](https://github.com/ctuning/ck-mxnet) (Apache)\n",
    "* [CK-NNTest](https://github.com/ctuning/ck-nntest) (cTuning foundation)\n",
    "* [CK-TensorFlow](https://github.com/ctuning/ck-tensorflow) (Google)\n",
    "* [CK-TensorRT](https://github.com/dividiti/ck-tensorrt) (NVIDIA)\n",
    "* etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [dividiti](http://dividiti.com)'s submission to [ReQuEST @ ASPLOS'18](http://cknowledge.org/request-cfp-asplos2018.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. [Overview](#overview)\n",
    "1. [Platforms](#platforms)\n",
    "  1. [HiKey 960](#platforms_hikey)\n",
    "  1. [Firefly RK3399](#platforms_firefly)\n",
    "1. [Experimental data](#data) [for developers]\n",
    "1. [Data wrangling code](#code) [for developers]\n",
    "1. [Experiments on HiKey 960](#experiments_hikey)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"overview\"></a>\n",
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Jupyter Notebook studies performance (execution time) vs accuracy (top1 / top5) using the [Arm Compute Library](https://github.com/ARM-software/ComputeLibrary) on two development platforms:\n",
    "- [HiKey 960](https://www.96boards.org/product/hikey960/);\n",
    "- [Firefly RK3399](http://en.t-firefly.com/index.php/product/rk3399.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"platforms\"></a>\n",
    "## Platforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"platforms_hikey\"></a>\n",
    "### HiKey 960"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  - Chip:\n",
    "     - [HiSilicon Kirin 960](http://www.hisilicon.com/en/Solutions/Kirin)\n",
    "  - CPU (\"performance\" / \"big\"):\n",
    "    - ARM&reg; Cortex&reg;-A73;\n",
    "    - Max clock 2362 MHz;\n",
    "    - 4 cores;\n",
    "  - CPU (\"efficiency\" / \"LITTLE\"):\n",
    "    - ARM&reg; Cortex&reg;-A53;\n",
    "    - Max clock 1844 MHz;\n",
    "    - 4 cores;\n",
    "  - GPU:\n",
    "    - ARM&reg; Mali&trade; G71 architecture;\n",
    "    - Max clock 1037 MHz;\n",
    "    - 8 cores;\n",
    "    - OpenCL driver (`hikey962`: `instr=1,clexperimental=1,softjobpatch`):\n",
    "```\n",
    "$ ck run program:tool-print-opencl-devices | grep \"version:\"\n",
    "OpenCL 2.0 v1.r6p0-01rel0.24c5f5e966f2b7f1f19b91d6f32ff53e\n",
    "```\n",
    "\n",
    "  - RAM:\n",
    "    - LPDDR4 SDRAM;\n",
    "    - 3 GB;\n",
    "\n",
    "  - BSP:\n",
    "    - Debian Stretch (9) Linux\n",
    "```\n",
    "$ uname -a\n",
    "Linux hikey962 4.4.74-00216-g10816f6 #3 SMP PREEMPT Thu Jul 6 14:38:42 BST 2017 aarch64 GNU/Linux\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hikey_model = 'HiKey960\\x00'\n",
    "hikey_name  = 'HiKey 960'\n",
    "hikey_id    = 'hikey-960'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"platforms_firefly\"></a>\n",
    "### Firefly RK3399"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  - Chip:\n",
    "    - [Rockchip RK3399](http://rockchip.wikidot.com/rk3399)\n",
    "  - CPU (\"big\"):\n",
    "    - ARM&reg; Cortex&reg;-A72 architecture\n",
    "    - Max clock 1800 MHz;\n",
    "    - 2 cores;\n",
    "  - CPU (\"LITTLE\"):\n",
    "    - ARM&reg; Cortex&reg;-A53 architecture;\n",
    "    - Max clock 1416 MHz;\n",
    "    - 4 cores;\n",
    "  - GPU:\n",
    "    - ARM&reg; Mali&trade;-T860 architecture;\n",
    "    - Max clock 800 MHz;\n",
    "    - 4 cores;\n",
    "    - OpenCL driver:\n",
    "```\n",
    "$ ck run program:tool-print-opencl-devices | grep \"version:\"\n",
    "v1.r13p0-00rel0-git(a4271c9).31ba04af2d3c01618138bef3aed66c2c\n",
    "```\n",
    "\n",
    "  - RAM:\n",
    "    - Samsung dual-channel DDR3;\n",
    "    - 4 GB (8 GB swap);\n",
    "  - BSP:\n",
    "    - [Firefly-rk3399_xubuntu1604_201711301130.7z](https://drive.google.com/drive/u/0/folders/1lbaR7XVyHT4SnXkJ2ybj5YXAzAjDBWfT)\n",
    "```\n",
    "$ cat /etc/lsb-release\n",
    "DISTRIB_ID=Ubuntu\n",
    "DISTRIB_RELEASE=16.04\n",
    "DISTRIB_CODENAME=xenial\n",
    "DISTRIB_DESCRIPTION=\"Ubuntu 16.04.4 LTS\"\n",
    "$ uname -a\n",
    "Linux firefly 4.4.77 #554 SMP Thu Nov 30 11:30:11 HKT 2017 aarch64 aarch64 aarch64 GNU/Linux\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "firefly_model = 'Rockchip RK3399 Firefly Board (Linux Opensource)\\x00'\n",
    "firefly_name  = 'Firefly RK3399'\n",
    "firefly_id    = 'firefly'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Platform mappings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_to_id = {\n",
    "    firefly_model : firefly_id,\n",
    "    hikey_model   : hikey_id\n",
    "}\n",
    "id_to_name = {\n",
    "    firefly_id : firefly_name,\n",
    "    hikey_id   : hikey_name\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"data\"></a>\n",
    "## Get the experimental data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The experimental data can be downloaded and registered with CK as described below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy experiments on 50,000 images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "$ wget https://www.dropbox.com/s/<...>/ck-request-asplos18-mobilenets-armcl-opencl-accuracy-50000.zip\n",
    "$ ck add repo --zip=ck-request-asplos18-mobilenets-armcl-opencl-accuracy-50000.zip\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy50000_repo_uoa = 'ck-request-asplos18-mobilenets-armcl-opencl-accuracy-50000'\n",
    "!ck list $accuracy50000_repo_uoa:experiment:* | sort"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy experiments on 500 images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "$ wget https://www.dropbox.com/s/<...>/ck-request-asplos18-mobilenets-armcl-opencl-accuracy-500.zip\n",
    "$ ck add repo --zip=ck-request-asplos18-mobilenets-armcl-opencl-accuracy-500.zip\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy500_repo_uoa = 'ck-request-asplos18-mobilenets-armcl-opencl-accuracy-500'\n",
    "!ck list $accuracy500_repo_uoa:experiment:* | sort"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance (latency) experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "$ wget https://www.dropbox.com/s/<...>/ck-request-asplos18-mobilenets-armcl-opencl-performance.zip\n",
    "$ ck add repo --zip=ck-request-asplos18-mobilenets-armcl-opencl-performance.zip\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "performance_repo_uoa = 'ck-request-asplos18-mobilenets-armcl-opencl-performance'\n",
    "!ck list $performance_repo_uoa:experiment:* | sort"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"code\"></a>\n",
    "## Data wrangling code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NB:** Please ignore this section if you are not interested in re-running or modifying this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Includes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Standard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scientific"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If some of the scientific packages are missing, please install them using:\n",
    "```\n",
    "# pip install jupyter pandas numpy matplotlib\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython as ip\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as mp\n",
    "import seaborn as sb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('IPython version: %s' % ip.__version__)\n",
    "print ('Pandas version: %s' % pd.__version__)\n",
    "print ('NumPy version: %s' % np.__version__)\n",
    "print ('Matplotlib version: %s' % mp.__version__)\n",
    "print ('Seaborn version: %s' % sb.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "def display_in_full(df):\n",
    "    pd.options.display.max_columns = len(df.columns)\n",
    "    pd.options.display.max_rows = len(df.index)\n",
    "    display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_colormap = cm.autumn\n",
    "default_fontsize = 16\n",
    "default_barwidth = 0.8\n",
    "default_figwidth = 24\n",
    "default_figheight = 3\n",
    "default_figdpi = 200\n",
    "default_figsize = [default_figwidth, default_figheight]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if mp.__version__[0]=='2': mp.style.use('classic')\n",
    "mp.rcParams['figure.max_open_warning'] = 200\n",
    "mp.rcParams['figure.dpi'] = default_figdpi\n",
    "mp.rcParams['font.size'] = default_fontsize\n",
    "mp.rcParams['legend.fontsize'] = 'medium'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Collective Knowledge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If CK is not installed, please install it using:\n",
    "```\n",
    "# pip install ck\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ck.kernel as ck\n",
    "print ('CK version: %s' % ck.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Access experimental data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_experimental_results(repo_uoa, tags='explore-mobilenets-performance', accuracy=False,\n",
    "                             module_uoa='experiment', _library=None, _platform=None):\n",
    "    r = ck.access({'action':'search', 'repo_uoa':repo_uoa, 'module_uoa':module_uoa, 'tags':tags})\n",
    "    if r['return']>0:\n",
    "        print('Error: %s' % r['error'])\n",
    "        exit(1)\n",
    "    experiments = r['lst']\n",
    "\n",
    "    dfs = []\n",
    "    for experiment in experiments:\n",
    "        data_uoa = experiment['data_uoa']\n",
    "        r = ck.access({'action':'list_points', 'repo_uoa':repo_uoa, 'module_uoa':module_uoa, 'data_uoa':data_uoa})\n",
    "        if r['return']>0:\n",
    "            print('Error: %s' % r['error'])\n",
    "            exit(1)\n",
    "        # Library.\n",
    "        library_tags = [ \n",
    "            tag for tag in r['dict']['tags']\n",
    "            if tag in [ '17.12-48bc34ea', '18.01-f45d5a9b', '18.03-e40997bb', 'request-d8f69c13' ]\n",
    "        ]\n",
    "        if len(library_tags)==1:\n",
    "            tag_to_library = {\n",
    "                # Library tags on HiKey.\n",
    "                '17.12-48bc34ea'        : '17.12',\n",
    "                '18.01-f45d5a9b'        : '18.01',\n",
    "                '18.03-e40997bb'        : '18.03',\n",
    "                'request-d8f69c13'      : 'dv/dt', # 18.03+\n",
    "                # TODO: Library tags on Firefly.\n",
    "                '17.12-48bc34e'         : '17.12',\n",
    "            }\n",
    "            library = tag_to_library[library_tags[0]]\n",
    "        else:\n",
    "            print('[Warning] Bad library tags. Skipping experiment with tags:')\n",
    "            print(r['dict']['tags'])\n",
    "            continue\n",
    "        if _library and _library!=library: continue\n",
    "        # For each point.    \n",
    "        for point in r['points']:\n",
    "            point_file_path = os.path.join(r['path'], 'ckp-%s.0001.json' % point)\n",
    "            with open(point_file_path) as point_file:\n",
    "                point_data_raw = json.load(point_file)\n",
    "            characteristics_list = point_data_raw['characteristics_list']\n",
    "            num_repetitions = len(characteristics_list)\n",
    "            platform = model_to_id[point_data_raw['features']['platform']['platform']['model']]\n",
    "            if _platform and _platform!=platform: continue\n",
    "            batch_size = np.int64(point_data_raw['choices']['env'].get('CK_BATCH_SIZE',-1))\n",
    "            batch_count = np.int64(point_data_raw['choices']['env'].get('CK_BATCH_COUNT',-1))\n",
    "            convolution_method = np.int64(point_data_raw['choices']['env'].get('CK_CONVOLUTION_METHOD_HINT',1))\n",
    "            multiplier = np.float64(point_data_raw['choices']['env'].get('CK_ENV_MOBILENET_WIDTH_MULTIPLIER',-1))\n",
    "            resolution = np.int64(point_data_raw['choices']['env'].get('CK_ENV_MOBILENET_RESOLUTION',-1))\n",
    "            model = 'v1-%.2f-%d' % (multiplier, resolution)\n",
    "            if accuracy:\n",
    "                data = [\n",
    "                    {\n",
    "                        # features\n",
    "                        'platform': platform,\n",
    "                        'library': library,\n",
    "                        # choices\n",
    "                        'model': model,\n",
    "                        'batch_size': batch_size,\n",
    "                        'batch_count': batch_count,\n",
    "                        'convolution_method': convolution_method,\n",
    "                        'resolution': resolution,\n",
    "                        'multiplier': multiplier,\n",
    "                        # statistical repetition\n",
    "                        'repetition_id': repetition_id,\n",
    "                        # runtime characteristics\n",
    "                        'success?': characteristics['run'].get('run_success', 'n/a'),\n",
    "                        'accuracy_top1': characteristics['run'].get('accuracy_top1', 0),\n",
    "                        'accuracy_top5': characteristics['run'].get('accuracy_top5', 0),\n",
    "                        # recompute accuracy from frame_predictions (was incorrectly recorded in early experiments)\n",
    "                        'accuracy_top1_': len([\n",
    "                            prediction for prediction in characteristics['run'].get('frame_predictions', [])\n",
    "                            if prediction['accuracy_top1']=='yes'\n",
    "                        ]) / np.float64(batch_count),\n",
    "                        'accuracy_top5_': len([\n",
    "                            prediction for prediction in characteristics['run'].get('frame_predictions', [])\n",
    "                            if prediction['accuracy_top5']=='yes'\n",
    "                        ]) / np.float64(batch_count)\n",
    "                    }\n",
    "                    for (repetition_id, characteristics) in zip(range(num_repetitions), characteristics_list)\n",
    "                ]\n",
    "            else: # performance\n",
    "                data = [\n",
    "                    {\n",
    "                        # features\n",
    "                        'platform': platform,\n",
    "                        'library': library,\n",
    "                        # choices\n",
    "                        'model': model,\n",
    "                        'batch_size': batch_size,\n",
    "                        'batch_count': batch_count,\n",
    "                        'convolution_method': convolution_method,\n",
    "                        'resolution': resolution,\n",
    "                        'multiplier': multiplier,\n",
    "                        # statistical repetition\n",
    "                        'repetition_id': repetition_id,\n",
    "                        # runtime characteristics\n",
    "                        'success?': characteristics['run'].get('run_success', 'n/a'),\n",
    "                        'time_avg_ms': characteristics['run']['prediction_time_avg_s']*1e+3,\n",
    "                        'time_total_ms': characteristics['run']['prediction_time_total_s']*1e+3,\n",
    "                    }\n",
    "                    for (repetition_id, characteristics) in zip(range(num_repetitions), characteristics_list)\n",
    "                ]\n",
    "            index = [\n",
    "                'platform', 'library', 'model', 'multiplier', 'resolution', 'convolution_method', 'batch_size', 'repetition_id'\n",
    "            ]\n",
    "            # Construct a DataFrame.\n",
    "            df = pd.DataFrame(data)\n",
    "            df = df.set_index(index)\n",
    "            # Append to the list of similarly constructed DataFrames.\n",
    "            dfs.append(df)\n",
    "    if dfs:\n",
    "        # Concatenate all thus constructed DataFrames (i.e. stack on top of each other).\n",
    "        result = pd.concat(dfs)\n",
    "        result.sort_index(ascending=True, inplace=True)\n",
    "    else:\n",
    "        # Construct a dummy DataFrame the success status of which can be safely checked.\n",
    "        result = pd.DataFrame(columns=['success?'])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge performance and accuracy data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return a new DataFrame with only the performance and accuracy metrics.\n",
    "def merge_performance_accuracy(df_performance, df_accuracy, reference_lib=None,\n",
    "                               performance_metric = 'time_avg_ms', accuracy_metric = 'accuracy_top1'):\n",
    "    df = df_performance[[performance_metric]]\n",
    "    accuracy_list = []\n",
    "    for index, row in df.iterrows():\n",
    "        (platform, lib, model, multiplier, resolution, convolution_method, batch_size) = index\n",
    "        if reference_lib: lib = reference_lib\n",
    "        accuracy = df_accuracy.loc[(platform, lib, model, multiplier, resolution, 1, batch_size)][accuracy_metric]\n",
    "        accuracy_list.append(accuracy)\n",
    "    df = df.assign(accuracy_top1=accuracy_list) # FIXME: assign to the value of accuracy_metric\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot experimental data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "def plot(df, performance_metric='time_avg_ms', accuracy_metric='accuracy_top1',\n",
    "         save_fig_name='mobilenets-armcl-opencl.png', fix=True):\n",
    "    fig = plt.figure(figsize=(8,4), dpi=200)\n",
    "    lib_to_color = { '17.12': 'cyan', '18.01' : 'magenta', '18.03' : 'orange', 'dv/dt' : 'green' }\n",
    "    multiplier_to_marker_0 = { 1.00 : '*', 0.75 : 'D', 0.50: 'v', 0.25 : '8' } # gemm\n",
    "    multiplier_to_marker_1 = { 1.00 : 'p', 0.75 : 's', 0.50: '^', 0.25 : 'o' } # direct\n",
    "\n",
    "    ax = fig.gca()\n",
    "    for index, row in df.iterrows():\n",
    "        (lib, model, multiplier, resolution, convolution_method, batch_size) = index\n",
    "        performance = row[performance_metric]\n",
    "        accuracy = row[accuracy_metric]\n",
    "        \n",
    "        # Mark Pareto-optimal points.\n",
    "        is_on_pareto = True\n",
    "        for index1, row1 in df.iterrows():\n",
    "            is_faster = row1[performance_metric] < row[performance_metric]\n",
    "            is_no_less_accurate = row1[accuracy_metric] >= row[accuracy_metric]\n",
    "            if is_faster and is_no_less_accurate:\n",
    "                is_on_pareto = False\n",
    "                break\n",
    "\n",
    "        # GEMM-based convolution should be exactly the same in '18.03' and 'dv/dt', so plot\n",
    "        # the minimum execution time of '18.03' and 'dv/dt' as '18.03'.\n",
    "        if fix and convolution_method==0 and (lib=='dv/dt' or lib=='18.03'):\n",
    "            performance_dv_dt = df.loc[('dv/dt', model, multiplier, resolution, convolution_method, batch_size)][performance_metric]\n",
    "            performance_18_03 = df.loc[('18.03', model, multiplier, resolution, convolution_method, batch_size)][performance_metric]\n",
    "            if lib=='18.03':\n",
    "                if (performance_dv_dt < performance_18_03):\n",
    "                    continue\n",
    "            if lib=='dv/dt':\n",
    "                if (performance_dv_dt < performance_18_03):\n",
    "                    lib = '18.03' # change color\n",
    "                else:\n",
    "                    continue\n",
    "\n",
    "        if convolution_method==0:\n",
    "            marker = multiplier_to_marker_0[multiplier]\n",
    "        else:\n",
    "            marker = multiplier_to_marker_1[multiplier]\n",
    "        color = lib_to_color[lib]\n",
    "        size = resolution / 16\n",
    "\n",
    "        ax.plot(performance, accuracy, marker, markerfacecolor=color, markersize=size)\n",
    "\n",
    "        # Mark Pareto-optimal points with scaled black pluses.\n",
    "        if is_on_pareto:\n",
    "            ax.plot(performance, accuracy, 'k+', markersize=size)\n",
    "\n",
    "    # Title.\n",
    "    ax.set_title('%s: Mali-G71 @ 807 MHz, FP32' % (id_to_name[hikey_id]))\n",
    "    # X axis.\n",
    "    xlabel='Image recognition time (ms)' if performance_metric=='time_avg_ms' else ''\n",
    "    ax.set_xlabel(xlabel)\n",
    "    ax.set_xlim(5.0, 65.1)\n",
    "    ax.set_xticks(np.arange(5.0, 65.1, 5.0))\n",
    "    for xtick in ax.xaxis.get_major_ticks(): xtick.label.set_fontsize(12)\n",
    "    # Y axis.\n",
    "    ylabel='ImageNet validation accuracy (top %s)' % accuracy_metric[-1]\n",
    "    ax.set_ylabel(ylabel)\n",
    "    ax.set_ylim(0.4, 0.751)\n",
    "    ax.set_yticks(np.arange(0.4, 0.751, 0.05))\n",
    "    for ytick in ax.yaxis.get_major_ticks(): ytick.label.set_fontsize(12)\n",
    "    # Legend.\n",
    "    handles = [ mp.patches.Patch(color=color, label=lib) for (lib, color) in lib_to_color.items() ]\n",
    "    plt.legend(title='Arm CL', handles=handles[::-1], loc='lower right')\n",
    "\n",
    "    plt.grid()\n",
    "    plt.savefig(save_fig_name, dpi=default_figdpi, bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"experiments_hikey\"></a>\n",
    "## Experiments on HiKey 960"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance (latency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_performance = get_experimental_results(repo_uoa=performance_repo_uoa, tags='explore-mobilenets-performance',\n",
    "                                          accuracy=False)\n",
    "# Take the minimum execution time out of several repetitions.\n",
    "df_performance = df_performance.groupby(level=df_performance.index.names[:-1]).min()\n",
    "# Display all rows and columns.\n",
    "# display_in_full(df_performance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy on 500 images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_accuracy500 = get_experimental_results(repo_uoa=accuracy500_repo_uoa, tags='explore-mobilenets-accuracy',\n",
    "                                          accuracy=True)\n",
    "# Reduce the repetition_id index dimension.\n",
    "df_accuracy500 = df_accuracy500 \\\n",
    "    .groupby(level=df_accuracy500.index.names[:-1]).min()\n",
    "# Display all rows and columns.\n",
    "display_in_full(df_accuracy500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy on 50,000 images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_accuracy50000 = get_experimental_results(repo_uoa=accuracy50000_repo_uoa, tags='explore-mobilenets-accuracy',\n",
    "                                            accuracy=True)\n",
    "# Reduce the repetition_id index dimension.\n",
    "df_accuracy50000 = df_accuracy50000 \\\n",
    "    .groupby(level=df_accuracy50000.index.names[:-1]).min()\n",
    "# Display all rows and columns.\n",
    "display_in_full(df_accuracy50000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot performance vs. Top 1 accuracy on 50,000 images (using the 'dv/dt' fork as reference lib)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_metric = 'top1_accuracy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_performance_accuracy50000 = merge_performance_accuracy(df_performance, df_accuracy50000, reference_lib='dv/dt')\n",
    "display_in_full(df_performance_accuracy50000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Only \"18.03\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot(df_performance_accuracy50000.loc[hikey_id].loc[['18.03']], accuracy_metric=accuracy_metric,\n",
    "#      save_fig_name='18_03.%s.50000.png' % accuracy_metric, fix=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### \"dv/dt\" vs. \"18.03\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot(df_performance_accuracy50000.loc[hikey_id].loc[['18.03','dv/dt']],\n",
    "#      save_fig_name='dv_dt+18_03.%s.50000.png' % accuracy_metric)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### \"dv/dt\" vs. \"18.03\" vs. \"18.01\" vs. \"17.12\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(df_performance_accuracy50000.loc[hikey_id],\n",
    "     save_fig_name='dv_dt+18_03+18_01+17_12.%s.50000.png' % (accuracy_metric+'_'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot performance vs. Top 1 accuracy on 500 images (using the 'dv/dt' fork as reference lib)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_performance_accuracy500 = merge_performance_accuracy(df_performance, df_accuracy500, reference_lib='dv/dt')\n",
    "display_in_full(df_performance_accuracy500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### \"dv/dt\" vs. \"18.03\" vs. \"18.01\" vs. \"17.12\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(df_performance_accuracy500.loc[hikey_id],\n",
    "     save_fig_name='dv_dt+18_03+18_01+17_12.%s.500.png' % (accuracy_metric+'_'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot performance vs. Top 1 accuracy on 500 images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_performance_accuracy500 = merge_performance_accuracy(df_performance, df_accuracy500)\n",
    "display_in_full(df_performance_accuracy500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### \"dv/dt\" vs. \"18.03\" vs. \"18.01\" vs. \"17.12\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(df_performance_accuracy500.loc[hikey_id],\n",
    "     save_fig_name='dv_dt+18_03+18_01+17_12.%s.500.png' % accuracy_metric)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
